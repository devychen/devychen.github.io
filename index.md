---
layout: homepage
---

## About Me

Currently seeking career opportunities in data-driven analytics professional.

In September, I will be a gradute in M.A. Computational Linguistics at the Univeristy of Tuebingen. <br>

I also hold these degrees: _MSc in Sociology_ at University of Oxford (UK), 
_BA in Linguistics and Sociology_ at the University of Manchester (UK). <br>

I have worked full-time at ByteDance as a marketing specialist at Game Publishing Business Sector, with a focus on partnership developments, growth and performance attribution. Previously also an assistant strategic consultant at Roland Berger and A.T.Kearney, and a TV producer at Mango TV (consider it as the Netflix in China). 

## Research Interests

- **LLM-Based Agent Simulations:**  AI(LLM) NPC, Conversational AI Companions.

## Professional Interests

- **Data-Driven **
- **Performance Marketing:** Digital products (Game, AI, etc...).

## Personal Interests

- Love music: game and film original soundtracks (no lyrics), musical, etc...
- I pratice **Kendo**, which is a Japanese martial art.

## Projects

**Three Detectives in a Room: Investigating Character Consistency in Multi-Agent LLM Dialogue** (Ongoing)
Github [Access](https://github.com/devychen/detective_sim)
*Abstract* As LLMs increasingly simulate fictional characters, their role-playing fluency is impressive but often inconsistent, harming dialogue believability. While prior work focuses on single-agent simulation or architectures, multi-agent character consistency remains understudied—especially from a linguistic perspective. This thesis examines how well LLM agents maintain distinct characters during collaborative tasks, addressing a key gap in understanding multi-agent interactions. By analyzing linguistic consistency in collective problem-solving, it explores whether current models can sustain coherent character identities beyond isolated exchanges.

**A Gradient Adjust Approach to Machine Unlearning** (Accepted. SemEval 2025 and ACL 2025)  
Github [Access](https://github.com/devychen/SemEval2025_Task4_NEKO) 
*Abstract* LLMs risk leaking sensitive data, making machine unlearning crucial. We propose gradient ascent forgetting with KL-divergence retention for a 1B-parameter model. While effective at unlearning, utility preservation remains challenging. Experiments reveal a key trade-off: stronger forgetting reduces performance. This highlights practical difficulties in machine unlearning, as seen in SemEval 2025’s Task 4.

**Experiencing Co-Creativity: The Practice and Evaluation of Writing Reality Show Scripts with ChatGPT-3.5 by Professionals** (Coursework. Graded 1.0)  
Github [Access](https://github.com/devychen/Course_LLM_Implications)
*Abstract* This project is a first attempt on the application of large language models (ChatGPT-3.5) into co-creating variety show scripts, practising and evaluating by professionals. Currently, the development of language models has brought profound effects on the content creation industry but the realm of variety show production does not seem to be explored. Based on quantitative questionnaires and qualitative interviews, this project highlights the advantages and disadvantages of ChatGPT-3.5 in casting and script writing, envisioning a fine-tuned co-writing system in the future.


**Emotion Recognition of Pedagogical Agents in Education** (Coursework. Graded 1.0. Waiting for publication.)  
Github [Access](https://github.com/devychen/Pedagogical_Agents_2023)
*Abstract* This study explores how a virtual instructor’s emotions (happy, content, frustrated, sad) affect learning in educational videos. Participants (N=300) accurately recognized the agent’s emotions, with happy rated highest for happiness, sad for sadness, etc. Surprisingly, learners exposed to frustrated/sad agents performed better than those with happy/content agents, though positive emotions were rated as more engaging. Findings suggest emotional expressions influence learning differently than perceived engagement, highlighting their complex role in education.


**The Relations Between Personality and Language Use** (Coursework. Graded 1.0)
Github [Access]
*Abstract* 
The study extract data from all series of Harry Potter films to analyse and investigate: Do language variables of the LIWC refect personality factors as in previous LIWC studies?

<!-- 
{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %} -->
